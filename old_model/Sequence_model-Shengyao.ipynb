{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30170, 60, 6)\n",
      "(30170, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.activations import sigmoid\n",
    "np.random.seed(1)\n",
    "from model_helper import load_test_case, divide_data\n",
    "from model_helper import corr_plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return (sigmoid(x)/5) - 0.1\n",
    "\n",
    "def all_stock_name():\n",
    "    filenames = os.listdir(path)\n",
    "    temp = [filename for filename in filenames if filename.endswith('.csv')]\n",
    "    #print temp\n",
    "    return [x.replace('.csv' ,'') for x in temp]\n",
    "\n",
    "\n",
    "def single_stock_data(stock_name):\n",
    "    data_path = os.path.join(path,stock_name+'.csv')\n",
    "    df = pd.DataFrame.from_csv(data_path,header = None, parse_dates=[[0, 1]])\n",
    "    df.columns = ['Open','High','Low','Close','Outstanding','Turnover']\n",
    "    # header=['date','time','open','high','low','close','outstanding','turnover']\n",
    "    return df\n",
    "\n",
    "\n",
    "def x_y_new(df):\n",
    "    N = 60\n",
    "    M = len(df) - N - 10\n",
    "    X = np.zeros((M,N,6))\n",
    "    Y = np.zeros((M,1))\n",
    "    Z = df.values\n",
    "    for i in range(M):\n",
    "        X[i, :, :] = Z[i:i+N,:]\n",
    "        forward = Z[i+N+1,3] -  Z[i+N,3]\n",
    "        now = Z[i+N,3] -  Z[i+N-1,3]\n",
    "        if forward * now < 0:\n",
    "            Y[i,0] = 1\n",
    "            \n",
    "    return X,Y\n",
    "        \n",
    "        \n",
    "\n",
    "def x_y_for_single_stock(df,stock_name):\n",
    "    print (stock_name)\n",
    "    all_dates = list(set([x.date() for x in df.index]))\n",
    "    all_dates.sort()\n",
    "    N = len(all_dates)-1\n",
    "    X = np.zeros((N,209,6,1))\n",
    "    Y = np.zeros((N,1))\n",
    "    pos = []\n",
    "    for i in range(N):\n",
    "        d1=all_dates[i]\n",
    "        d2=all_dates[i+1]\n",
    "\n",
    "        x_start,x_end = return_x_time(d1)\n",
    "        #print x_start, x_end\n",
    "        x_df = df[x_start:x_end]\n",
    "        temp_x = x_df.values\n",
    "        temp_x = np.diff(temp_x,axis=0)\n",
    "        X[i, :, :, :] = temp_x.reshape((209, 6, 1))\n",
    "\n",
    "        y_start, y_end = return_y_time(d1)\n",
    "        y_df = df[y_start:y_end]\n",
    "        Y[i,0] = y_singal(y_df)\n",
    "        pos.append([stock_name,d1])\n",
    "\n",
    "    return X,Y,pos\n",
    "\n",
    "def return_x_time(date):\n",
    "    return (dt.datetime(date.year,date.month,date.day,9,0),\n",
    "            dt.datetime(date.year, date.month, date.day, 14, 30))\n",
    "\n",
    "def y_singal(df):\n",
    "    price1 = float(df[df.index == df.index.min()]['Close'])\n",
    "    price2 = float(df[df.index == df.index.max()]['Close'])\n",
    "    return float(price2 - price1)/price1\n",
    "\n",
    "def number_to_category(num):\n",
    "    return\n",
    "\n",
    "\n",
    "def return_y_time(d1):\n",
    "    return (dt.datetime(d1.year,d1.month,d1.day,14,30),\n",
    "            dt.datetime(d1.year, d1.month, d1.day, 14,31))\n",
    "\n",
    "\n",
    "path = r\"data\"\n",
    "all_names = all_stock_name()\n",
    "    #print all_names\n",
    "    \n",
    "Pos = []\n",
    "\n",
    "name = all_names[2]\n",
    "df = single_stock_data(name)\n",
    "X,Y = x_y_new(df)\n",
    "    \n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133.747 133.747 133.747 133.747   0.      0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(X[3,3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[462.]\n"
     ]
    }
   ],
   "source": [
    "print(sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76.]\n"
     ]
    }
   ],
   "source": [
    "X = X [0:5000,:,:]\n",
    "Y = Y [0:5000,:]\n",
    "print(sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Price_Forecast\n",
    "def Price_Forecast(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the Price_Forecast model's graph.\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    embeddings = Input(shape=input_shape, dtype=np.float32)\n",
    "    N =32\n",
    "    \n",
    "    print(embeddings.shape, \"....\")\n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    X = LSTM(N, return_sequences=True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    \n",
    "    X = LSTM(N)(embeddings)\n",
    "    \n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(1, activation = 'softmax')(X)\n",
    "\n",
    "    # Create Model instance which converts embeddings into X.\n",
    "    model = Model(embeddings, X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return model\n",
    "\n",
    "def custom_activation(x):\n",
    "    return (sigmoid(x)/50) - 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 6)\n",
      "(?, 480, 6) ....\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 480, 6)            0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 32)                4992      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,025\n",
      "Trainable params: 5,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(4750, 60, 6)\n",
      "(4750, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_21 to have shape (480, 6) but got array with shape (60, 6)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-d46cf6ab4342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# evaluate the model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_21 to have shape (480, 6) but got array with shape (60, 6)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from keras.optimizers import adam\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = divide_data(X, Y)\n",
    "\n",
    "\n",
    "inputShape = (480, 6)\n",
    "print(inputShape)\n",
    "model = Price_Forecast(inputShape)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(train_features.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "\n",
    "model.fit(train_features,train_labels, epochs=5, batch_size=128, shuffle=True)\n",
    "\n",
    "    # evaluate the model performance\n",
    "    #loss, acc = model.evaluate(np.squeeze(test_features, axis=3), test_labels)\n",
    "    #print(\"Test accuracy = \", acc)\n",
    "# test_predict = model.predict(test_features)\n",
    "# train_predict = model.predict(train_features)\n",
    "\n",
    "# corr_plt(train_predict,train_labels)\n",
    "# corr_plt(test_predict,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(train_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

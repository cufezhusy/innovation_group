{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5312sEasBeYc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from keras.models import Model,Sequential,save_model,load_model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation,BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===================================================================================\n",
    "# Data loading part\n",
    "# ===================================================================================\n",
    "def all_stock_name():\n",
    "    filenames = os.listdir(path)\n",
    "    temp = [filename for filename in filenames if filename.endswith('.csv')]\n",
    "    # print temp\n",
    "    return [x.replace('.csv', '') for x in temp]\n",
    "\n",
    "def single_stock_data(stock_name):\n",
    "    data_path = os.path.join(path, stock_name + '.csv')\n",
    "    df = pd.DataFrame.from_csv(data_path, header=None, parse_dates=[[0, 1]])\n",
    "    df.columns = ['Open', 'High', 'Low', 'Close', 'Outstanding', 'Turnover']\n",
    "    # header=['date','time','open','high','low','close','outstanding','turnover']\n",
    "    return df\n",
    "  \n",
    "def get_file_from_csv(data_path):\n",
    "    df = pd.DataFrame.from_csv(data_path, header=None, parse_dates=[[0, 1]])\n",
    "    df.columns = ['Open', 'High', 'Low', 'Close', 'Outstanding', 'Turnover']\n",
    "    # header=['date','time','open','high','low','close','outstanding','turnover']\n",
    "    return df\n",
    "\n",
    "def divide_data(X,Y):\n",
    "    return train_test_split(X, Y,test_size = 0.05, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "def norm_ts(Z):\n",
    "    Z_norm = (Z - Z.min()) / (Z.max() - Z.min())\n",
    "    invert_func = lambda X: (Z.max() - Z.min())*X + Z.min()\n",
    "    return Z_norm,invert_func\n",
    "\n",
    "\n",
    "def one_step_predict(model,train_features, train_labels):\n",
    "    model.fit(train_features, train_labels, epochs=1, batch_size=64, shuffle=True)\n",
    "    return model\n",
    "\n",
    "# ===================================================================================\n",
    "# Visualization the model\n",
    "# ===================================================================================\n",
    "def animation_train_and_test(train_labels, test_labels, predict_spread_1, predict_spread_2):\n",
    "    # Configure the training plot\n",
    "    fig = plt.figure()\n",
    "    axes1 = fig.add_subplot(121)\n",
    "    axes2 = fig.add_subplot(122)\n",
    "    line, = axes1.plot(train_labels, np.zeros(train_labels.shape), 'ro')\n",
    "    axes1.set_title('High Price')\n",
    "    axes1.set_xlabel('Actual')\n",
    "    axes1.set_ylabel('Model')\n",
    "    line2, = axes2.plot(test_labels, np.zeros(test_labels.shape), 'bo')\n",
    "    axes2.set_title('Low Price')\n",
    "    axes2.set_xlabel('Actual')\n",
    "    axes2.set_ylabel('Model')\n",
    "    axes1.set_ylim([0, 1])\n",
    "    axes2.set_ylim([0, 1])\n",
    "\n",
    "    def corr_plt(data):\n",
    "        line.set_ydata(data)\n",
    "        return line,\n",
    "\n",
    "    def corr_plt2(data):\n",
    "        line2.set_ydata(data)\n",
    "        return line2,\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, corr_plt, predict_spread_1, interval=1000)\n",
    "    ani2 = animation.FuncAnimation(fig, corr_plt2, predict_spread_2, interval=1000)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def very_simple_benchmark_model(X):\n",
    "    daytimes = X.shape[1]\n",
    "    x2 = np.linspace(0, daytimes - 1, num=daytimes)\n",
    "    out = np.zeros((X.shape[0],1))\n",
    "    for s in range(X.shape[0]):\n",
    "        y1 = X[s,:,0]\n",
    "        z = np.polyfit(x2, y1, 2)\n",
    "        f = np.poly1d(z)\n",
    "        out[s, 0] = f(daytimes)\n",
    "    return out\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ],
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37303,
     "status": "ok",
     "timestamp": 1521980429279,
     "user": {
      "displayName": "Shengyao Zhu",
      "photoUrl": "//lh6.googleusercontent.com/-VNGlsIecUiQ/AAAAAAAAAAI/AAAAAAAABMw/unjAgsJoFRE/s50-c-k-no/photo.jpg",
      "userId": "101418951298501362533"
     },
     "user_tz": -120
    },
    "id": "Zdx63qoUOB_x",
    "outputId": "470b296b-64df-4aee-b9d5-6a3612e69c1b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1521983164409,
     "user": {
      "displayName": "Shengyao Zhu",
      "photoUrl": "//lh6.googleusercontent.com/-VNGlsIecUiQ/AAAAAAAAAAI/AAAAAAAABMw/unjAgsJoFRE/s50-c-k-no/photo.jpg",
      "userId": "101418951298501362533"
     },
     "user_tz": -120
    },
    "id": "pKZeS0tbiaqQ",
    "outputId": "5a7fe63d-adde-4d5c-8d81-24cec0ad69a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\working\\ML_Python\\Python3\\python-3.6.2.amd64\\lib\\site-packages\\ipykernel_launcher.py:29: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import adam\n",
    "import random\n",
    "\n",
    "path = r\"C:\\working\\data_2012_07_2012_12\\data\\SH600036.csv\"\n",
    "df = get_file_from_csv(path)\n",
    "dev_set = 20000\n",
    "# random time\n",
    "time_list = df.index.tolist()\n",
    "lookback = 20\n",
    "timewindow = 30\n",
    "indices = random.sample(range(lookback+1, len(time_list)-timewindow), dev_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uKWDnKVKmwjW"
   },
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# Generate x and y\n",
    "# ===================================================================================\n",
    "def x_y_new(df,indices,outlier_prob=0.5,time_window =60,lookback = 55):\n",
    "    M = len(indices)\n",
    "    N = time_window +1\n",
    "    # add time demension\n",
    "    X = np.zeros((M, N, 2, 1))\n",
    "    Y = np.zeros((M))\n",
    "    \n",
    "    \n",
    "    # get the close price from the df\n",
    "    raw_Z = np.zeros((len(df),7))\n",
    "    raw_Z[:,0:6] = df.values\n",
    "    raw_Z[:,6] = [x.value for x in df.index]\n",
    "    \n",
    "    norm_Z,invert_func = norm_ts(raw_Z[:,3])\n",
    "    \n",
    "    # generate trades\n",
    "    for i in range(M):\n",
    "        \n",
    "      # take a snapshot from the original time series around the trading time\n",
    "      z_local = norm_Z[indices[i] - lookback : indices[i] - lookback + time_window ]\n",
    "        \n",
    "      # create a two line array, one is benchmark trade line, one is actual trade line.\n",
    "      # the only differences between the two line is the point on actual tradeing time\n",
    "      # the benchmark line is average between last and next trades, the actual trade line is the actual price\n",
    "      local_x = np.zeros((N,2,1))\n",
    "      \n",
    "      # firstly we create a benchmark trades line, the benchmark trades line contain all normal trades\n",
    "      # and the price on trading time is calculated by average of the two\n",
    "      local_x[0:lookback,0,0] = z_local[0:lookback]\n",
    "      local_x[lookback+1:,0,0] = z_local[lookback:]\n",
    "      local_x[lookback,0,0] = (z_local[lookback-1] + z_local[lookback])/2.0\n",
    "    \n",
    "      # then we generate the actual trade line\n",
    "      local_x[:,1,0] = local_x[:,0,0]\n",
    "      reasonable_range = local_x[lookback-5:lookback+3,0,0]\n",
    "      min_reasonable = min(reasonable_range)\n",
    "      max_reasonable = max(reasonable_range)\n",
    "      temp = random.random()\n",
    "      if temp > 0.5:\n",
    "        trade_price = random.random()*(max_reasonable - min_reasonable) + min_reasonable\n",
    "        Y[i] = 0.0\n",
    "      elif temp > 0.25:\n",
    "        trade_price = random.random()*(max_reasonable - min_reasonable) + max_reasonable\n",
    "        Y[i] = 1.0\n",
    "      else:\n",
    "        trade_price = -random.random()*(max_reasonable - min_reasonable) + min_reasonable\n",
    "        Y[i] = 1.0\n",
    "      local_x[lookback,1,0] = trade_price\n",
    "      \n",
    "      local_x,_ = norm_ts(local_x)\n",
    "        \n",
    "        \n",
    "      X[i,:,:,:] = local_x  \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R29S4aqIvcMu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 31, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "X,Y = x_y_new(df,indices,lookback = lookback,time_window = timewindow)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1521983428251,
     "user": {
      "displayName": "Shengyao Zhu",
      "photoUrl": "//lh6.googleusercontent.com/-VNGlsIecUiQ/AAAAAAAAAAI/AAAAAAAABMw/unjAgsJoFRE/s50-c-k-no/photo.jpg",
      "userId": "101418951298501362533"
     },
     "user_tz": -120
    },
    "id": "ruqjAhzfNxC8",
    "outputId": "9accd16f-9c0f-4758-d44d-396109653fb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28f2e4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idx = 1453\n",
    "plt.plot(X[idx,:,1,0],'b*' )\n",
    "plt.plot(X[idx,:,0,0],'r*-' )\n",
    "plt.show()\n",
    "print(Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1521983175842,
     "user": {
      "displayName": "Shengyao Zhu",
      "photoUrl": "//lh6.googleusercontent.com/-VNGlsIecUiQ/AAAAAAAAAAI/AAAAAAAABMw/unjAgsJoFRE/s50-c-k-no/photo.jpg",
      "userId": "101418951298501362533"
     },
     "user_tz": -120
    },
    "id": "4Zis3iBuBeZi",
    "outputId": "e9d5d190-d69c-461a-b34f-7c4d14e74d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 19000\n",
      "number of test examples = 1000\n",
      "X_train shape: (19000, 31, 2, 1)\n",
      "Y_train shape: (19000, 2)\n",
      "X_test shape: (1000, 31, 2, 1)\n",
      "Y_test shape: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# Loading the data (signs)\n",
    "X_train,  X_test, Y_train_orig,Y_test_orig= divide_data(X,Y)\n",
    "\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "num_classes = 2\n",
    "Y_train = keras.utils.to_categorical(Y_train_orig.T, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test_orig.T, num_classes)\n",
    "\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2x7CvSBaBeZM"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(48, (4, 4),padding='same',input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Conv2D(16, (4, 4),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4),padding='same'))\n",
    "model.add(Conv2D(16, (4, 4),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4),padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2210,
     "output_extras": [
      {
       "item_id": 9
      },
      {
       "item_id": 31
      },
      {
       "item_id": 59
      },
      {
       "item_id": 96
      },
      {
       "item_id": 134
      },
      {
       "item_id": 173
      },
      {
       "item_id": 201
      },
      {
       "item_id": 221
      },
      {
       "item_id": 258
      },
      {
       "item_id": 260
      },
      {
       "item_id": 261
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82634,
     "status": "ok",
     "timestamp": 1521983266742,
     "user": {
      "displayName": "Shengyao Zhu",
      "photoUrl": "//lh6.googleusercontent.com/-VNGlsIecUiQ/AAAAAAAAAAI/AAAAAAAABMw/unjAgsJoFRE/s50-c-k-no/photo.jpg",
      "userId": "101418951298501362533"
     },
     "user_tz": -120
    },
    "id": "m-dbnyV0CK7c",
    "outputId": "23f9f367-b9f9-4631-aa19-5224266ca1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 31, 2, 48)         816       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 31, 2, 48)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 16, 1, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 16, 1, 16)         12304     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 4, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 4, 1, 16)          4112      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 17,266\n",
      "Trainable params: 17,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "19000/19000 [==============================] - 5s 247us/step - loss: 0.6927 - acc: 0.5014 - val_loss: 0.6923 - val_acc: 0.4980\n",
      "Epoch 2/100\n",
      "19000/19000 [==============================] - 4s 199us/step - loss: 0.6907 - acc: 0.5243 - val_loss: 0.6891 - val_acc: 0.5270\n",
      "Epoch 3/100\n",
      "19000/19000 [==============================] - 4s 197us/step - loss: 0.6840 - acc: 0.6235 - val_loss: 0.6800 - val_acc: 0.5630\n",
      "Epoch 4/100\n",
      "19000/19000 [==============================] - 4s 205us/step - loss: 0.6652 - acc: 0.7121 - val_loss: 0.6532 - val_acc: 0.7160\n",
      "Epoch 5/100\n",
      "19000/19000 [==============================] - 4s 214us/step - loss: 0.6277 - acc: 0.7567 - val_loss: 0.6104 - val_acc: 0.7260\n",
      "Epoch 6/100\n",
      "19000/19000 [==============================] - 4s 216us/step - loss: 0.5761 - acc: 0.7728 - val_loss: 0.5633 - val_acc: 0.7590\n",
      "Epoch 7/100\n",
      "19000/19000 [==============================] - 4s 217us/step - loss: 0.5282 - acc: 0.7841 - val_loss: 0.5225 - val_acc: 0.7680\n",
      "Epoch 8/100\n",
      "19000/19000 [==============================] - 4s 212us/step - loss: 0.4935 - acc: 0.7913 - val_loss: 0.4968 - val_acc: 0.7750\n",
      "Epoch 9/100\n",
      "19000/19000 [==============================] - 4s 221us/step - loss: 0.4679 - acc: 0.7986 - val_loss: 0.4818 - val_acc: 0.7840\n",
      "Epoch 10/100\n",
      "19000/19000 [==============================] - 4s 235us/step - loss: 0.4498 - acc: 0.8063 - val_loss: 0.4696 - val_acc: 0.7670\n",
      "Epoch 11/100\n",
      "19000/19000 [==============================] - 4s 235us/step - loss: 0.4355 - acc: 0.8118 - val_loss: 0.4499 - val_acc: 0.7910\n",
      "Epoch 12/100\n",
      "19000/19000 [==============================] - 5s 238us/step - loss: 0.4222 - acc: 0.8171 - val_loss: 0.4385 - val_acc: 0.8030\n",
      "Epoch 13/100\n",
      "19000/19000 [==============================] - 4s 213us/step - loss: 0.4110 - acc: 0.8210 - val_loss: 0.4402 - val_acc: 0.7850\n",
      "Epoch 14/100\n",
      "19000/19000 [==============================] - 4s 216us/step - loss: 0.4012 - acc: 0.8247 - val_loss: 0.4181 - val_acc: 0.8080\n",
      "Epoch 15/100\n",
      "19000/19000 [==============================] - 4s 218us/step - loss: 0.3917 - acc: 0.8306 - val_loss: 0.4199 - val_acc: 0.7970\n",
      "Epoch 16/100\n",
      "19000/19000 [==============================] - 4s 235us/step - loss: 0.3834 - acc: 0.8352 - val_loss: 0.4011 - val_acc: 0.8070\n",
      "Epoch 17/100\n",
      "19000/19000 [==============================] - 4s 233us/step - loss: 0.3744 - acc: 0.8396 - val_loss: 0.3925 - val_acc: 0.8160\n",
      "Epoch 18/100\n",
      "19000/19000 [==============================] - 5s 237us/step - loss: 0.3680 - acc: 0.8411 - val_loss: 0.3829 - val_acc: 0.8190\n",
      "Epoch 19/100\n",
      "19000/19000 [==============================] - 4s 232us/step - loss: 0.3614 - acc: 0.8448 - val_loss: 0.3748 - val_acc: 0.8320\n",
      "Epoch 20/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.3538 - acc: 0.8493 - val_loss: 0.3671 - val_acc: 0.8410\n",
      "Epoch 21/100\n",
      "19000/19000 [==============================] - 4s 235us/step - loss: 0.3493 - acc: 0.8516 - val_loss: 0.3610 - val_acc: 0.8430\n",
      "Epoch 22/100\n",
      "19000/19000 [==============================] - 4s 231us/step - loss: 0.3433 - acc: 0.8536 - val_loss: 0.3547 - val_acc: 0.8450\n",
      "Epoch 23/100\n",
      "19000/19000 [==============================] - 4s 236us/step - loss: 0.3400 - acc: 0.8539 - val_loss: 0.3493 - val_acc: 0.8490\n",
      "Epoch 24/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.3330 - acc: 0.8582 - val_loss: 0.3473 - val_acc: 0.8460\n",
      "Epoch 25/100\n",
      "19000/19000 [==============================] - 4s 233us/step - loss: 0.3291 - acc: 0.8602 - val_loss: 0.3425 - val_acc: 0.8480\n",
      "Epoch 26/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.3259 - acc: 0.8585 - val_loss: 0.3350 - val_acc: 0.8610\n",
      "Epoch 27/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.3218 - acc: 0.8641 - val_loss: 0.3407 - val_acc: 0.8450\n",
      "Epoch 28/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.3181 - acc: 0.8651 - val_loss: 0.3270 - val_acc: 0.8580\n",
      "Epoch 29/100\n",
      "19000/19000 [==============================] - 4s 236us/step - loss: 0.3145 - acc: 0.8661 - val_loss: 0.3213 - val_acc: 0.8600\n",
      "Epoch 30/100\n",
      "19000/19000 [==============================] - 4s 236us/step - loss: 0.3110 - acc: 0.8670 - val_loss: 0.3206 - val_acc: 0.8560\n",
      "Epoch 31/100\n",
      "19000/19000 [==============================] - 4s 235us/step - loss: 0.3095 - acc: 0.8668 - val_loss: 0.3145 - val_acc: 0.8620\n",
      "Epoch 32/100\n",
      "19000/19000 [==============================] - 4s 223us/step - loss: 0.3061 - acc: 0.8711 - val_loss: 0.3112 - val_acc: 0.8630\n",
      "Epoch 33/100\n",
      "19000/19000 [==============================] - 4s 215us/step - loss: 0.3026 - acc: 0.8718 - val_loss: 0.3118 - val_acc: 0.8660\n",
      "Epoch 34/100\n",
      "19000/19000 [==============================] - 4s 209us/step - loss: 0.3020 - acc: 0.8703 - val_loss: 0.3084 - val_acc: 0.8670\n",
      "Epoch 35/100\n",
      "19000/19000 [==============================] - 4s 221us/step - loss: 0.2981 - acc: 0.8723 - val_loss: 0.3009 - val_acc: 0.8750\n",
      "Epoch 36/100\n",
      "19000/19000 [==============================] - 4s 223us/step - loss: 0.2955 - acc: 0.8738 - val_loss: 0.2984 - val_acc: 0.8750\n",
      "Epoch 37/100\n",
      "19000/19000 [==============================] - 4s 226us/step - loss: 0.2924 - acc: 0.8752 - val_loss: 0.2958 - val_acc: 0.8780\n",
      "Epoch 38/100\n",
      "19000/19000 [==============================] - 4s 226us/step - loss: 0.2905 - acc: 0.8755 - val_loss: 0.2944 - val_acc: 0.8780\n",
      "Epoch 39/100\n",
      "19000/19000 [==============================] - 4s 226us/step - loss: 0.2891 - acc: 0.8761 - val_loss: 0.2907 - val_acc: 0.8810\n",
      "Epoch 40/100\n",
      "19000/19000 [==============================] - 4s 227us/step - loss: 0.2877 - acc: 0.8762 - val_loss: 0.2895 - val_acc: 0.8720\n",
      "Epoch 41/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.2852 - acc: 0.8772 - val_loss: 0.2905 - val_acc: 0.8740\n",
      "Epoch 42/100\n",
      "19000/19000 [==============================] - 4s 217us/step - loss: 0.2821 - acc: 0.8794 - val_loss: 0.2834 - val_acc: 0.8820\n",
      "Epoch 43/100\n",
      "19000/19000 [==============================] - 4s 221us/step - loss: 0.2824 - acc: 0.8785 - val_loss: 0.2859 - val_acc: 0.8710\n",
      "Epoch 44/100\n",
      "19000/19000 [==============================] - 4s 216us/step - loss: 0.2796 - acc: 0.8808 - val_loss: 0.2817 - val_acc: 0.8740\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000/19000 [==============================] - 4s 200us/step - loss: 0.2771 - acc: 0.8815 - val_loss: 0.2778 - val_acc: 0.8820\n",
      "Epoch 46/100\n",
      "19000/19000 [==============================] - 4s 198us/step - loss: 0.2751 - acc: 0.8823 - val_loss: 0.2834 - val_acc: 0.8830\n",
      "Epoch 47/100\n",
      "19000/19000 [==============================] - 4s 201us/step - loss: 0.2740 - acc: 0.8829 - val_loss: 0.2760 - val_acc: 0.8800\n",
      "Epoch 48/100\n",
      "19000/19000 [==============================] - 4s 201us/step - loss: 0.2714 - acc: 0.8843 - val_loss: 0.2749 - val_acc: 0.8760\n",
      "Epoch 49/100\n",
      "19000/19000 [==============================] - 4s 200us/step - loss: 0.2705 - acc: 0.8834 - val_loss: 0.2818 - val_acc: 0.8770\n",
      "Epoch 50/100\n",
      "19000/19000 [==============================] - 4s 199us/step - loss: 0.2715 - acc: 0.8855 - val_loss: 0.2696 - val_acc: 0.8810\n",
      "Epoch 51/100\n",
      "19000/19000 [==============================] - 4s 199us/step - loss: 0.2676 - acc: 0.8835 - val_loss: 0.2682 - val_acc: 0.8820\n",
      "Epoch 52/100\n",
      "19000/19000 [==============================] - 4s 210us/step - loss: 0.2669 - acc: 0.8849 - val_loss: 0.2676 - val_acc: 0.8800\n",
      "Epoch 53/100\n",
      "19000/19000 [==============================] - 4s 223us/step - loss: 0.2647 - acc: 0.8870 - val_loss: 0.2682 - val_acc: 0.8810\n",
      "Epoch 54/100\n",
      "19000/19000 [==============================] - 4s 206us/step - loss: 0.2636 - acc: 0.8873 - val_loss: 0.2648 - val_acc: 0.8860\n",
      "Epoch 55/100\n",
      "19000/19000 [==============================] - 4s 206us/step - loss: 0.2625 - acc: 0.8872 - val_loss: 0.2628 - val_acc: 0.8870\n",
      "Epoch 56/100\n",
      "19000/19000 [==============================] - 4s 206us/step - loss: 0.2606 - acc: 0.8884 - val_loss: 0.2622 - val_acc: 0.8870\n",
      "Epoch 57/100\n",
      "19000/19000 [==============================] - 4s 206us/step - loss: 0.2595 - acc: 0.8888 - val_loss: 0.2633 - val_acc: 0.8840\n",
      "Epoch 58/100\n",
      "19000/19000 [==============================] - 4s 203us/step - loss: 0.2572 - acc: 0.8897 - val_loss: 0.2607 - val_acc: 0.8840\n",
      "Epoch 59/100\n",
      "19000/19000 [==============================] - 4s 204us/step - loss: 0.2558 - acc: 0.8908 - val_loss: 0.2582 - val_acc: 0.8880\n",
      "Epoch 60/100\n",
      "19000/19000 [==============================] - 4s 207us/step - loss: 0.2548 - acc: 0.8917 - val_loss: 0.2563 - val_acc: 0.8880\n",
      "Epoch 61/100\n",
      "19000/19000 [==============================] - 4s 222us/step - loss: 0.2551 - acc: 0.8898 - val_loss: 0.2583 - val_acc: 0.8820\n",
      "Epoch 62/100\n",
      "19000/19000 [==============================] - 4s 220us/step - loss: 0.2536 - acc: 0.8923 - val_loss: 0.2576 - val_acc: 0.8890\n",
      "Epoch 63/100\n",
      "19000/19000 [==============================] - 4s 220us/step - loss: 0.2514 - acc: 0.8935 - val_loss: 0.2533 - val_acc: 0.8890\n",
      "Epoch 64/100\n",
      "19000/19000 [==============================] - 4s 220us/step - loss: 0.2506 - acc: 0.8925 - val_loss: 0.2555 - val_acc: 0.8940\n",
      "Epoch 65/100\n",
      "19000/19000 [==============================] - 4s 221us/step - loss: 0.2487 - acc: 0.8932 - val_loss: 0.2523 - val_acc: 0.8890\n",
      "Epoch 66/100\n",
      "19000/19000 [==============================] - 4s 220us/step - loss: 0.2481 - acc: 0.8934 - val_loss: 0.2521 - val_acc: 0.8860\n",
      "Epoch 67/100\n",
      "19000/19000 [==============================] - 4s 224us/step - loss: 0.2475 - acc: 0.8936 - val_loss: 0.2504 - val_acc: 0.8870\n",
      "Epoch 68/100\n",
      "19000/19000 [==============================] - 5s 239us/step - loss: 0.2460 - acc: 0.8948 - val_loss: 0.2500 - val_acc: 0.8910\n",
      "Epoch 69/100\n",
      "19000/19000 [==============================] - 5s 240us/step - loss: 0.2452 - acc: 0.8958 - val_loss: 0.2480 - val_acc: 0.8940\n",
      "Epoch 70/100\n",
      "19000/19000 [==============================] - 4s 233us/step - loss: 0.2435 - acc: 0.8969 - val_loss: 0.2467 - val_acc: 0.8920\n",
      "Epoch 71/100\n",
      "19000/19000 [==============================] - 4s 237us/step - loss: 0.2438 - acc: 0.8944 - val_loss: 0.2536 - val_acc: 0.8940\n",
      "Epoch 72/100\n",
      "19000/19000 [==============================] - 4s 230us/step - loss: 0.2425 - acc: 0.8946 - val_loss: 0.2544 - val_acc: 0.8850\n",
      "Epoch 73/100\n",
      "19000/19000 [==============================] - 4s 236us/step - loss: 0.2400 - acc: 0.8979 - val_loss: 0.2462 - val_acc: 0.8900\n",
      "Epoch 74/100\n",
      "19000/19000 [==============================] - 4s 226us/step - loss: 0.2398 - acc: 0.8964 - val_loss: 0.2500 - val_acc: 0.8900\n",
      "Epoch 75/100\n",
      "19000/19000 [==============================] - 4s 218us/step - loss: 0.2392 - acc: 0.8969 - val_loss: 0.2427 - val_acc: 0.8960\n",
      "Epoch 76/100\n",
      "19000/19000 [==============================] - 4s 212us/step - loss: 0.2386 - acc: 0.8978 - val_loss: 0.2446 - val_acc: 0.8910\n",
      "Epoch 77/100\n",
      "19000/19000 [==============================] - 4s 213us/step - loss: 0.2372 - acc: 0.8982 - val_loss: 0.2434 - val_acc: 0.9010\n",
      "Epoch 78/100\n",
      "19000/19000 [==============================] - 4s 228us/step - loss: 0.2360 - acc: 0.8980 - val_loss: 0.2396 - val_acc: 0.8970\n",
      "Epoch 79/100\n",
      "19000/19000 [==============================] - 4s 233us/step - loss: 0.2355 - acc: 0.8982 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 80/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.2356 - acc: 0.8982 - val_loss: 0.2491 - val_acc: 0.8960\n",
      "Epoch 81/100\n",
      "19000/19000 [==============================] - 4s 234us/step - loss: 0.2333 - acc: 0.8993 - val_loss: 0.2615 - val_acc: 0.8830\n",
      "Epoch 82/100\n",
      "19000/19000 [==============================] - 4s 236us/step - loss: 0.2324 - acc: 0.9005 - val_loss: 0.2398 - val_acc: 0.9040\n",
      "Epoch 83/100\n",
      "19000/19000 [==============================] - 4s 216us/step - loss: 0.2304 - acc: 0.9003 - val_loss: 0.2397 - val_acc: 0.8950\n",
      "Epoch 84/100\n",
      "19000/19000 [==============================] - 4s 217us/step - loss: 0.2310 - acc: 0.9000 - val_loss: 0.2350 - val_acc: 0.9030\n",
      "Epoch 85/100\n",
      "19000/19000 [==============================] - 4s 219us/step - loss: 0.2312 - acc: 0.8998 - val_loss: 0.2406 - val_acc: 0.8980\n",
      "Epoch 86/100\n",
      "19000/19000 [==============================] - 4s 219us/step - loss: 0.2299 - acc: 0.9015 - val_loss: 0.2355 - val_acc: 0.9030\n",
      "Epoch 87/100\n",
      "19000/19000 [==============================] - 4s 210us/step - loss: 0.2292 - acc: 0.9007 - val_loss: 0.2321 - val_acc: 0.9020\n",
      "Epoch 88/100\n",
      "19000/19000 [==============================] - 4s 216us/step - loss: 0.2268 - acc: 0.9039 - val_loss: 0.2360 - val_acc: 0.9010\n",
      "Epoch 89/100\n",
      "19000/19000 [==============================] - 5s 281us/step - loss: 0.2273 - acc: 0.9011 - val_loss: 0.2329 - val_acc: 0.8930\n",
      "Epoch 90/100\n",
      "19000/19000 [==============================] - 4s 224us/step - loss: 0.2269 - acc: 0.9023 - val_loss: 0.2299 - val_acc: 0.9010\n",
      "Epoch 91/100\n",
      "19000/19000 [==============================] - 4s 236us/step - loss: 0.2256 - acc: 0.9033 - val_loss: 0.2307 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "19000/19000 [==============================] - 4s 215us/step - loss: 0.2254 - acc: 0.9023 - val_loss: 0.2307 - val_acc: 0.8990\n",
      "Epoch 93/100\n",
      "19000/19000 [==============================] - 4s 232us/step - loss: 0.2236 - acc: 0.9034 - val_loss: 0.2278 - val_acc: 0.9020\n",
      "Epoch 94/100\n",
      "19000/19000 [==============================] - 5s 249us/step - loss: 0.2234 - acc: 0.9036 - val_loss: 0.2369 - val_acc: 0.8990\n",
      "Epoch 95/100\n",
      "19000/19000 [==============================] - 4s 220us/step - loss: 0.2222 - acc: 0.9054 - val_loss: 0.2267 - val_acc: 0.9030\n",
      "Epoch 96/100\n",
      "19000/19000 [==============================] - 4s 215us/step - loss: 0.2217 - acc: 0.9051 - val_loss: 0.2260 - val_acc: 0.9050\n",
      "Epoch 97/100\n",
      "19000/19000 [==============================] - 4s 221us/step - loss: 0.2213 - acc: 0.9049 - val_loss: 0.2302 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "19000/19000 [==============================] - 4s 235us/step - loss: 0.2198 - acc: 0.9058 - val_loss: 0.2284 - val_acc: 0.8980\n",
      "Epoch 99/100\n",
      "19000/19000 [==============================] - 4s 222us/step - loss: 0.2195 - acc: 0.9067 - val_loss: 0.2228 - val_acc: 0.9060\n",
      "Epoch 100/100\n",
      "19000/19000 [==============================] - 4s 217us/step - loss: 0.2198 - acc: 0.9056 - val_loss: 0.2332 - val_acc: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3a9908>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=100,\n",
    "              epochs=100,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 182,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 523,
     "status": "error",
     "timestamp": 1521980693351,
     "user": {
      "displayName": "Shengyao Zhu",
      "photoUrl": "//lh6.googleusercontent.com/-VNGlsIecUiQ/AAAAAAAAAAI/AAAAAAAABMw/unjAgsJoFRE/s50-c-k-no/photo.jpg",
      "userId": "101418951298501362533"
     },
     "user_tz": -120
    },
    "id": "aKk1IWh1E58q",
    "outputId": "71a3bf32-a071-46e9-a845-3ac8f0137ac4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9694061e-01, 3.0593653e-03],\n",
       "       [6.9098252e-01, 3.0901751e-01],\n",
       "       [6.7956018e-01, 3.2043979e-01],\n",
       "       ...,\n",
       "       [2.8659301e-04, 9.9971336e-01],\n",
       "       [2.6289956e-03, 9.9737096e-01],\n",
       "       [2.8808215e-01, 7.1191788e-01]], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gfcX-ZyQBeaA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\working\\innovation_group\\cnn_model\\final_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "cnn_outlier_prototype.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
